{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97011f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID#</th>\n",
       "      <th>Topflight</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Qual_miles</th>\n",
       "      <th>cc1_miles?</th>\n",
       "      <th>cc2_miles?</th>\n",
       "      <th>cc3_miles?</th>\n",
       "      <th>Bonus_miles</th>\n",
       "      <th>Bonus_trans</th>\n",
       "      <th>Flight_miles_12mo</th>\n",
       "      <th>Flight_trans_12</th>\n",
       "      <th>Online_12</th>\n",
       "      <th>Email</th>\n",
       "      <th>Club_member</th>\n",
       "      <th>Any_cc_miles_12mo</th>\n",
       "      <th>Phone_sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19244.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4123.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97752.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43300.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>5006.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10013.0</td>\n",
       "      <td>2436.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>5007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4832.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>5008.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4985.0</td>\n",
       "      <td>4985.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4987 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID#  Topflight  Balance  Qual_miles  cc1_miles?  cc2_miles?  \\\n",
       "0        1.0        0.0  28143.0         0.0         0.0         1.0   \n",
       "1        2.0        0.0  19244.0         0.0         0.0         0.0   \n",
       "2        3.0        0.0  41354.0         0.0         1.0         0.0   \n",
       "3        4.0        0.0  14776.0         0.0         0.0         0.0   \n",
       "4        5.0        1.0  97752.0         0.0         1.0         0.0   \n",
       "...      ...        ...      ...         ...         ...         ...   \n",
       "4982  5006.0        0.0  10013.0      2436.0         0.0         0.0   \n",
       "4983  5007.0        0.0   4832.0         0.0         0.0         0.0   \n",
       "4984  5008.0        0.0    500.0         0.0         0.0         0.0   \n",
       "4985     NaN        NaN      NaN         NaN         NaN         NaN   \n",
       "4986     NaN        NaN      NaN         NaN         NaN         NaN   \n",
       "\n",
       "      cc3_miles?  Bonus_miles  Bonus_trans  Flight_miles_12mo  \\\n",
       "0            0.0        174.0          1.0                0.0   \n",
       "1            0.0        215.0          2.0                0.0   \n",
       "2            0.0       4123.0          4.0                0.0   \n",
       "3            0.0        500.0          1.0                0.0   \n",
       "4            0.0      43300.0         26.0             2077.0   \n",
       "...          ...          ...          ...                ...   \n",
       "4982         0.0          0.0          0.0                0.0   \n",
       "4983         0.0          0.0          0.0                0.0   \n",
       "4984         0.0          0.0          0.0                0.0   \n",
       "4985         NaN          NaN          NaN                NaN   \n",
       "4986         NaN       4985.0       4985.0                NaN   \n",
       "\n",
       "      Flight_trans_12  Online_12  Email  Club_member  Any_cc_miles_12mo  \\\n",
       "0                 0.0        0.0    1.0          0.0                1.0   \n",
       "1                 0.0        0.0    0.0          0.0                0.0   \n",
       "2                 0.0        0.0    1.0          0.0                1.0   \n",
       "3                 0.0        0.0    1.0          0.0                0.0   \n",
       "4                 4.0        0.0    1.0          0.0                1.0   \n",
       "...               ...        ...    ...          ...                ...   \n",
       "4982              0.0        0.0    1.0          0.0                0.0   \n",
       "4983              0.0        0.0    1.0          0.0                0.0   \n",
       "4984              0.0        0.0    0.0          0.0                0.0   \n",
       "4985              NaN        NaN    NaN          NaN                NaN   \n",
       "4986              NaN        NaN    NaN          NaN                NaN   \n",
       "\n",
       "      Phone_sale  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "...          ...  \n",
       "4982         0.0  \n",
       "4983         0.0  \n",
       "4984         0.0  \n",
       "4985         NaN  \n",
       "4986         NaN  \n",
       "\n",
       "[4987 rows x 16 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "df = pd.read_excel('EastWestAirlinesNN.xls',sheet_name='data')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf7490b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID#                  True\n",
       "Topflight            True\n",
       "Balance              True\n",
       "Qual_miles           True\n",
       "cc1_miles?           True\n",
       "cc2_miles?           True\n",
       "cc3_miles?           True\n",
       "Bonus_miles          True\n",
       "Bonus_trans          True\n",
       "Flight_miles_12mo    True\n",
       "Flight_trans_12      True\n",
       "Online_12            True\n",
       "Email                True\n",
       "Club_member          True\n",
       "Any_cc_miles_12mo    True\n",
       "Phone_sale           True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df7aa285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4985, 16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(how='any',axis=0) \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64a5a9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    4330\n",
       "1.0     655\n",
       "Name: Phone_sale, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking class balance\n",
    "df['Phone_sale'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "034b6c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/cp84b1jn2f16p5scv8xkzyzh0000gn/T/ipykernel_19444/2282820844.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['Balance','Qual_miles','Bonus_miles','Bonus_trans','Flight_miles_12mo','Flight_trans_12','Online_12']] = sc.fit_transform(X[['Balance','Qual_miles','Bonus_miles','Bonus_trans','Flight_miles_12mo','Flight_trans_12','Online_12']])\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X = df.iloc[:, 1:15]\n",
    "y = df.iloc[:,-1]\n",
    "X[['Balance','Qual_miles','Bonus_miles','Bonus_trans','Flight_miles_12mo','Flight_trans_12','Online_12']] = sc.fit_transform(X[['Balance','Qual_miles','Bonus_miles','Bonus_trans','Flight_miles_12mo','Flight_trans_12','Online_12']])\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set  \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 22,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd03066a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 22:26:59.791974: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4416 - accuracy: 0.8686\n",
      "Epoch 2/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3904 - accuracy: 0.8704\n",
      "Epoch 3/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3873 - accuracy: 0.8704\n",
      "Epoch 4/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3777 - accuracy: 0.8704\n",
      "Epoch 5/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3800 - accuracy: 0.8704\n",
      "Epoch 6/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3773 - accuracy: 0.8704\n",
      "Epoch 7/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3748 - accuracy: 0.8704\n",
      "Epoch 8/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3713 - accuracy: 0.8704\n",
      "Epoch 9/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3733 - accuracy: 0.8704\n",
      "Epoch 10/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3741 - accuracy: 0.8704\n",
      "Epoch 11/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3716 - accuracy: 0.8704\n",
      "Epoch 12/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3732 - accuracy: 0.8704\n",
      "Epoch 13/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3721 - accuracy: 0.8704\n",
      "Epoch 14/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3717 - accuracy: 0.8704\n",
      "Epoch 15/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3686 - accuracy: 0.8704\n",
      "Epoch 16/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3690 - accuracy: 0.8704\n",
      "Epoch 17/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3727 - accuracy: 0.8704\n",
      "Epoch 18/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3685 - accuracy: 0.8704\n",
      "Epoch 19/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3696 - accuracy: 0.8704\n",
      "Epoch 20/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3700 - accuracy: 0.8704\n",
      "Epoch 21/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3707 - accuracy: 0.8704\n",
      "Epoch 22/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3731 - accuracy: 0.8704\n",
      "Epoch 23/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3681 - accuracy: 0.8704\n",
      "Epoch 24/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3675 - accuracy: 0.8704\n",
      "Epoch 25/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3692 - accuracy: 0.8704\n",
      "Epoch 26/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3682 - accuracy: 0.8704\n",
      "Epoch 27/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3700 - accuracy: 0.8704\n",
      "Epoch 28/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3686 - accuracy: 0.8704\n",
      "Epoch 29/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3710 - accuracy: 0.8704\n",
      "Epoch 30/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3681 - accuracy: 0.8704\n",
      "Epoch 31/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3703 - accuracy: 0.8704\n",
      "Epoch 32/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3711 - accuracy: 0.8704\n",
      "Epoch 33/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3693 - accuracy: 0.8704\n",
      "Epoch 34/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3677 - accuracy: 0.8704\n",
      "Epoch 35/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3676 - accuracy: 0.8704\n",
      "Epoch 36/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3688 - accuracy: 0.8704\n",
      "Epoch 37/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3692 - accuracy: 0.8704\n",
      "Epoch 38/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3679 - accuracy: 0.8704\n",
      "Epoch 39/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3677 - accuracy: 0.8704\n",
      "Epoch 40/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3681 - accuracy: 0.8704\n",
      "Epoch 41/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3673 - accuracy: 0.8704\n",
      "Epoch 42/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3670 - accuracy: 0.8704\n",
      "Epoch 43/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3688 - accuracy: 0.8704\n",
      "Epoch 44/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3678 - accuracy: 0.8704\n",
      "Epoch 45/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3673 - accuracy: 0.8704\n",
      "Epoch 46/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3681 - accuracy: 0.8704\n",
      "Epoch 47/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3709 - accuracy: 0.8704\n",
      "Epoch 48/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3697 - accuracy: 0.8704\n",
      "Epoch 49/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3679 - accuracy: 0.8704\n",
      "Epoch 50/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3671 - accuracy: 0.8704\n",
      "Epoch 51/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3658 - accuracy: 0.8704\n",
      "Epoch 52/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3661 - accuracy: 0.8704\n",
      "Epoch 53/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3693 - accuracy: 0.8704\n",
      "Epoch 54/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3685 - accuracy: 0.8704\n",
      "Epoch 55/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3698 - accuracy: 0.8704\n",
      "Epoch 56/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3675 - accuracy: 0.8704\n",
      "Epoch 57/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3690 - accuracy: 0.8704\n",
      "Epoch 58/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3667 - accuracy: 0.8704\n",
      "Epoch 59/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3683 - accuracy: 0.8704\n",
      "Epoch 60/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3649 - accuracy: 0.8704\n",
      "Epoch 61/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3658 - accuracy: 0.8704\n",
      "Epoch 62/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3660 - accuracy: 0.8704\n",
      "Epoch 63/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3666 - accuracy: 0.8704\n",
      "Epoch 64/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3673 - accuracy: 0.8704\n",
      "Epoch 65/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3659 - accuracy: 0.8704\n",
      "Epoch 66/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3664 - accuracy: 0.8704\n",
      "Epoch 67/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3668 - accuracy: 0.8704\n",
      "Epoch 68/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3668 - accuracy: 0.8704\n",
      "Epoch 69/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3672 - accuracy: 0.8704\n",
      "Epoch 70/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3668 - accuracy: 0.8704\n",
      "Epoch 71/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3668 - accuracy: 0.8704\n",
      "Epoch 72/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3672 - accuracy: 0.8704\n",
      "Epoch 73/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3662 - accuracy: 0.8704\n",
      "Epoch 74/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3658 - accuracy: 0.8704\n",
      "Epoch 75/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3660 - accuracy: 0.8704\n",
      "Epoch 76/3000\n",
      "399/399 [==============================] - 2s 6ms/step - loss: 0.3659 - accuracy: 0.8704\n",
      "Epoch 77/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3666 - accuracy: 0.8704\n",
      "Epoch 78/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3687 - accuracy: 0.8704\n",
      "Epoch 79/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3643 - accuracy: 0.8704\n",
      "Epoch 80/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3670 - accuracy: 0.8704\n",
      "Epoch 81/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3661 - accuracy: 0.8704\n",
      "Epoch 82/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3676 - accuracy: 0.8704\n",
      "Epoch 83/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3682 - accuracy: 0.8704\n",
      "Epoch 84/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3642 - accuracy: 0.8704\n",
      "Epoch 85/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3663 - accuracy: 0.8704\n",
      "Epoch 86/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3644 - accuracy: 0.8704\n",
      "Epoch 87/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3661 - accuracy: 0.8704\n",
      "Epoch 88/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3658 - accuracy: 0.8704\n",
      "Epoch 89/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3626 - accuracy: 0.8704\n",
      "Epoch 90/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3653 - accuracy: 0.8704\n",
      "Epoch 91/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3673 - accuracy: 0.8704\n",
      "Epoch 92/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8704\n",
      "Epoch 93/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3684 - accuracy: 0.8704\n",
      "Epoch 94/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3648 - accuracy: 0.8704\n",
      "Epoch 95/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3653 - accuracy: 0.8704\n",
      "Epoch 96/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3640 - accuracy: 0.8704\n",
      "Epoch 97/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3658 - accuracy: 0.8704\n",
      "Epoch 98/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3646 - accuracy: 0.8704\n",
      "Epoch 99/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8704\n",
      "Epoch 100/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3655 - accuracy: 0.8704\n",
      "Epoch 101/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8704\n",
      "Epoch 102/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8704\n",
      "Epoch 103/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3674 - accuracy: 0.8704\n",
      "Epoch 104/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3652 - accuracy: 0.8704\n",
      "Epoch 105/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3642 - accuracy: 0.8704\n",
      "Epoch 106/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3632 - accuracy: 0.8704\n",
      "Epoch 107/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3686 - accuracy: 0.8704\n",
      "Epoch 108/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3633 - accuracy: 0.8704\n",
      "Epoch 109/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8704\n",
      "Epoch 110/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3659 - accuracy: 0.8704\n",
      "Epoch 111/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3655 - accuracy: 0.8704\n",
      "Epoch 112/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3655 - accuracy: 0.8704\n",
      "Epoch 113/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3637 - accuracy: 0.8704\n",
      "Epoch 114/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8704\n",
      "Epoch 115/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3662 - accuracy: 0.8704\n",
      "Epoch 116/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3648 - accuracy: 0.8704\n",
      "Epoch 117/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.8704\n",
      "Epoch 118/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3663 - accuracy: 0.8704\n",
      "Epoch 119/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3635 - accuracy: 0.8704\n",
      "Epoch 120/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3638 - accuracy: 0.8704\n",
      "Epoch 121/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3634 - accuracy: 0.8704\n",
      "Epoch 122/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3654 - accuracy: 0.8704\n",
      "Epoch 123/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8704\n",
      "Epoch 124/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3654 - accuracy: 0.8704\n",
      "Epoch 125/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3645 - accuracy: 0.8704\n",
      "Epoch 126/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.8704\n",
      "Epoch 127/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.8704\n",
      "Epoch 128/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3670 - accuracy: 0.8704\n",
      "Epoch 129/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.8704\n",
      "Epoch 130/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3670 - accuracy: 0.8704\n",
      "Epoch 131/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3647 - accuracy: 0.8704\n",
      "Epoch 132/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3660 - accuracy: 0.8704\n",
      "Epoch 133/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3660 - accuracy: 0.8704\n",
      "Epoch 134/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3606 - accuracy: 0.8704\n",
      "Epoch 135/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3675 - accuracy: 0.8704\n",
      "Epoch 136/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8704\n",
      "Epoch 137/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3638 - accuracy: 0.8704\n",
      "Epoch 138/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3658 - accuracy: 0.8704\n",
      "Epoch 139/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3641 - accuracy: 0.8704\n",
      "Epoch 140/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3635 - accuracy: 0.8704\n",
      "Epoch 141/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3648 - accuracy: 0.8704\n",
      "Epoch 142/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8704\n",
      "Epoch 143/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3647 - accuracy: 0.8704\n",
      "Epoch 144/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3651 - accuracy: 0.8704\n",
      "Epoch 145/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8704\n",
      "Epoch 146/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3646 - accuracy: 0.8704\n",
      "Epoch 147/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3662 - accuracy: 0.8704\n",
      "Epoch 148/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3627 - accuracy: 0.8704\n",
      "Epoch 149/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3633 - accuracy: 0.8704\n",
      "Epoch 150/3000\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.3640 - accuracy: 0.8704\n",
      "Epoch 151/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3652 - accuracy: 0.8704\n",
      "Epoch 152/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3628 - accuracy: 0.8704\n",
      "Epoch 153/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3642 - accuracy: 0.8704\n",
      "Epoch 154/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3625 - accuracy: 0.8704\n",
      "Epoch 155/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3625 - accuracy: 0.8704\n",
      "Epoch 156/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3661 - accuracy: 0.8704\n",
      "Epoch 157/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3658 - accuracy: 0.8704\n",
      "Epoch 158/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8704\n",
      "Epoch 159/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3630 - accuracy: 0.8704\n",
      "Epoch 160/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3675 - accuracy: 0.8704\n",
      "Epoch 161/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3632 - accuracy: 0.8704\n",
      "Epoch 162/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3627 - accuracy: 0.8704\n",
      "Epoch 163/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3650 - accuracy: 0.8704\n",
      "Epoch 164/3000\n",
      "399/399 [==============================] - 2s 6ms/step - loss: 0.3634 - accuracy: 0.8704\n",
      "Epoch 165/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3632 - accuracy: 0.8704\n",
      "Epoch 166/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3638 - accuracy: 0.8704\n",
      "Epoch 167/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3642 - accuracy: 0.8704\n",
      "Epoch 168/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3640 - accuracy: 0.8704\n",
      "Epoch 169/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3678 - accuracy: 0.8704\n",
      "Epoch 170/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3644 - accuracy: 0.8704\n",
      "Epoch 171/3000\n",
      "399/399 [==============================] - 2s 6ms/step - loss: 0.3635 - accuracy: 0.8704\n",
      "Epoch 172/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3653 - accuracy: 0.8704\n",
      "Epoch 173/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8704\n",
      "Epoch 174/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8704\n",
      "Epoch 175/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3626 - accuracy: 0.8704\n",
      "Epoch 176/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3653 - accuracy: 0.8704\n",
      "Epoch 177/3000\n",
      "399/399 [==============================] - 3s 8ms/step - loss: 0.3631 - accuracy: 0.8704\n",
      "Epoch 178/3000\n",
      "399/399 [==============================] - 4s 11ms/step - loss: 0.3641 - accuracy: 0.8704\n",
      "Epoch 179/3000\n",
      "399/399 [==============================] - 4s 9ms/step - loss: 0.3678 - accuracy: 0.8704\n",
      "Epoch 180/3000\n",
      "399/399 [==============================] - 4s 9ms/step - loss: 0.3652 - accuracy: 0.8704\n",
      "Epoch 181/3000\n",
      "399/399 [==============================] - 4s 10ms/step - loss: 0.3628 - accuracy: 0.8704\n",
      "Epoch 182/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3626 - accuracy: 0.8704\n",
      "Epoch 183/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3610 - accuracy: 0.8704\n",
      "Epoch 184/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.8704\n",
      "Epoch 185/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3652 - accuracy: 0.8704\n",
      "Epoch 186/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3652 - accuracy: 0.8704\n",
      "Epoch 187/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3645 - accuracy: 0.8704\n",
      "Epoch 188/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8704\n",
      "Epoch 189/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3650 - accuracy: 0.8704\n",
      "Epoch 190/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3633 - accuracy: 0.8704\n",
      "Epoch 191/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3652 - accuracy: 0.8704\n",
      "Epoch 192/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3651 - accuracy: 0.8704\n",
      "Epoch 193/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3635 - accuracy: 0.8704\n",
      "Epoch 194/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.8704\n",
      "Epoch 195/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3636 - accuracy: 0.8704\n",
      "Epoch 196/3000\n",
      "399/399 [==============================] - 6s 15ms/step - loss: 0.3662 - accuracy: 0.8704\n",
      "Epoch 197/3000\n",
      "399/399 [==============================] - 3s 7ms/step - loss: 0.3619 - accuracy: 0.8704\n",
      "Epoch 198/3000\n",
      "399/399 [==============================] - 3s 6ms/step - loss: 0.3629 - accuracy: 0.8704\n",
      "Epoch 199/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3630 - accuracy: 0.8704\n",
      "Epoch 200/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3619 - accuracy: 0.8704\n",
      "Epoch 201/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3647 - accuracy: 0.8704\n",
      "Epoch 202/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3648 - accuracy: 0.8704\n",
      "Epoch 203/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3638 - accuracy: 0.8704\n",
      "Epoch 204/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3673 - accuracy: 0.8704\n",
      "Epoch 205/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3625 - accuracy: 0.8704\n",
      "Epoch 206/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3624 - accuracy: 0.8704\n",
      "Epoch 207/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3626 - accuracy: 0.8704\n",
      "Epoch 208/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3638 - accuracy: 0.8704\n",
      "Epoch 209/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3642 - accuracy: 0.8704\n",
      "Epoch 210/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3603 - accuracy: 0.8704\n",
      "Epoch 211/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3642 - accuracy: 0.8704\n",
      "Epoch 212/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3652 - accuracy: 0.8704\n",
      "Epoch 213/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3636 - accuracy: 0.8704\n",
      "Epoch 214/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3632 - accuracy: 0.8704\n",
      "Epoch 215/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3635 - accuracy: 0.8704\n",
      "Epoch 216/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3628 - accuracy: 0.8704\n",
      "Epoch 217/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3605 - accuracy: 0.8704\n",
      "Epoch 218/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3633 - accuracy: 0.8704\n",
      "Epoch 219/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3647 - accuracy: 0.8704\n",
      "Epoch 220/3000\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.3620 - accuracy: 0.8704\n",
      "Epoch 221/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3626 - accuracy: 0.8704\n",
      "Epoch 222/3000\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.3642 - accuracy: 0.8704\n",
      "Epoch 223/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3654 - accuracy: 0.8704\n",
      "Epoch 224/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3619 - accuracy: 0.8704\n",
      "Epoch 225/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8704\n",
      "Epoch 226/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8704\n",
      "Epoch 227/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3647 - accuracy: 0.8704\n",
      "Epoch 228/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3614 - accuracy: 0.8704\n",
      "Epoch 229/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3651 - accuracy: 0.8704\n",
      "Epoch 230/3000\n",
      "399/399 [==============================] - 3s 7ms/step - loss: 0.3600 - accuracy: 0.8704\n",
      "Epoch 231/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3605 - accuracy: 0.8704\n",
      "Epoch 232/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8704\n",
      "Epoch 233/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3644 - accuracy: 0.8704\n",
      "Epoch 234/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3613 - accuracy: 0.8704\n",
      "Epoch 235/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3617 - accuracy: 0.8704\n",
      "Epoch 236/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3644 - accuracy: 0.8704\n",
      "Epoch 237/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3633 - accuracy: 0.8704\n",
      "Epoch 238/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3651 - accuracy: 0.8704\n",
      "Epoch 239/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3642 - accuracy: 0.8704\n",
      "Epoch 240/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3623 - accuracy: 0.8704\n",
      "Epoch 241/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3621 - accuracy: 0.8704\n",
      "Epoch 242/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3624 - accuracy: 0.8704\n",
      "Epoch 243/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3630 - accuracy: 0.8704\n",
      "Epoch 244/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3639 - accuracy: 0.8704\n",
      "Epoch 245/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3610 - accuracy: 0.8704\n",
      "Epoch 246/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3646 - accuracy: 0.8704\n",
      "Epoch 247/3000\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.3640 - accuracy: 0.8704\n",
      "Epoch 248/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3611 - accuracy: 0.8704\n",
      "Epoch 249/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3618 - accuracy: 0.8704\n",
      "Epoch 250/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3624 - accuracy: 0.8704\n",
      "Epoch 251/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3625 - accuracy: 0.8704\n",
      "Epoch 252/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3606 - accuracy: 0.8704\n",
      "Epoch 253/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3636 - accuracy: 0.8704\n",
      "Epoch 254/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3617 - accuracy: 0.8704\n",
      "Epoch 255/3000\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.3666 - accuracy: 0.8704\n",
      "Epoch 256/3000\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.3643 - accuracy: 0.8704\n",
      "Epoch 257/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3629 - accuracy: 0.8704\n",
      "Epoch 258/3000\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.3644 - accuracy: 0.8704\n",
      "Epoch 259/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3633 - accuracy: 0.8704\n",
      "Epoch 260/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8704\n",
      "Epoch 261/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3633 - accuracy: 0.8704\n",
      "Epoch 262/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3613 - accuracy: 0.8704\n",
      "Epoch 263/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3623 - accuracy: 0.8704\n",
      "Epoch 264/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3633 - accuracy: 0.8704\n",
      "Epoch 265/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.8704\n",
      "Epoch 266/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8704\n",
      "Epoch 267/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3632 - accuracy: 0.8704\n",
      "Epoch 268/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3629 - accuracy: 0.8704\n",
      "Epoch 269/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8704\n",
      "Epoch 270/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3600 - accuracy: 0.8704\n",
      "Epoch 271/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8704\n",
      "Epoch 272/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3603 - accuracy: 0.8704\n",
      "Epoch 273/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3640 - accuracy: 0.8704\n",
      "Epoch 274/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3650 - accuracy: 0.8704\n",
      "Epoch 275/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3609 - accuracy: 0.8704\n",
      "Epoch 276/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3623 - accuracy: 0.8704\n",
      "Epoch 277/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3640 - accuracy: 0.8704\n",
      "Epoch 278/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8704\n",
      "Epoch 279/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3628 - accuracy: 0.8704\n",
      "Epoch 280/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8704\n",
      "Epoch 281/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3622 - accuracy: 0.8704\n",
      "Epoch 282/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3606 - accuracy: 0.8704\n",
      "Epoch 283/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3666 - accuracy: 0.8704\n",
      "Epoch 284/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3611 - accuracy: 0.8704\n",
      "Epoch 285/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3622 - accuracy: 0.8704\n",
      "Epoch 286/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3604 - accuracy: 0.8704\n",
      "Epoch 287/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8704\n",
      "Epoch 288/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3613 - accuracy: 0.8704\n",
      "Epoch 289/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3631 - accuracy: 0.8704\n",
      "Epoch 290/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8704\n",
      "Epoch 291/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3610 - accuracy: 0.8704\n",
      "Epoch 292/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8704\n",
      "Epoch 293/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8704\n",
      "Epoch 294/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3621 - accuracy: 0.8704\n",
      "Epoch 295/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3658 - accuracy: 0.8704\n",
      "Epoch 296/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8704\n",
      "Epoch 297/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8704\n",
      "Epoch 298/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3619 - accuracy: 0.8704\n",
      "Epoch 299/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3592 - accuracy: 0.8704\n",
      "Epoch 300/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3626 - accuracy: 0.8704\n",
      "Epoch 301/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3643 - accuracy: 0.8704\n",
      "Epoch 302/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3631 - accuracy: 0.8704\n",
      "Epoch 303/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3637 - accuracy: 0.8704\n",
      "Epoch 304/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3609 - accuracy: 0.8704\n",
      "Epoch 305/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3646 - accuracy: 0.8704\n",
      "Epoch 306/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3632 - accuracy: 0.8704\n",
      "Epoch 307/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3631 - accuracy: 0.8704\n",
      "Epoch 308/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3628 - accuracy: 0.8704\n",
      "Epoch 309/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3632 - accuracy: 0.8704\n",
      "Epoch 310/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3622 - accuracy: 0.8704\n",
      "Epoch 311/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3646 - accuracy: 0.8704\n",
      "Epoch 312/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3625 - accuracy: 0.8704\n",
      "Epoch 313/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3616 - accuracy: 0.8704\n",
      "Epoch 314/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3643 - accuracy: 0.8704\n",
      "Epoch 315/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3619 - accuracy: 0.8704\n",
      "Epoch 316/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3626 - accuracy: 0.8704\n",
      "Epoch 317/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3607 - accuracy: 0.8704\n",
      "Epoch 318/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3610 - accuracy: 0.8704\n",
      "Epoch 319/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3631 - accuracy: 0.8704\n",
      "Epoch 320/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8704\n",
      "Epoch 321/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3667 - accuracy: 0.8704\n",
      "Epoch 322/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3601 - accuracy: 0.8704\n",
      "Epoch 323/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3624 - accuracy: 0.8704\n",
      "Epoch 324/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3646 - accuracy: 0.8704\n",
      "Epoch 325/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8704\n",
      "Epoch 326/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3658 - accuracy: 0.8704\n",
      "Epoch 327/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8704\n",
      "Epoch 328/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3643 - accuracy: 0.8704\n",
      "Epoch 329/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3624 - accuracy: 0.8704\n",
      "Epoch 330/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.8704\n",
      "Epoch 331/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3640 - accuracy: 0.8704\n",
      "Epoch 332/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3648 - accuracy: 0.8704\n",
      "Epoch 333/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8704\n",
      "Epoch 334/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3595 - accuracy: 0.8704\n",
      "Epoch 335/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8704\n",
      "Epoch 336/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3648 - accuracy: 0.8704\n",
      "Epoch 337/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3589 - accuracy: 0.8704\n",
      "Epoch 338/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3651 - accuracy: 0.8704\n",
      "Epoch 339/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3630 - accuracy: 0.8704\n",
      "Epoch 340/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3611 - accuracy: 0.8704\n",
      "Epoch 341/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8704\n",
      "Epoch 342/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3606 - accuracy: 0.8704\n",
      "Epoch 343/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3626 - accuracy: 0.8704\n",
      "Epoch 344/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3623 - accuracy: 0.8704\n",
      "Epoch 345/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3639 - accuracy: 0.8704\n",
      "Epoch 346/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3628 - accuracy: 0.8704\n",
      "Epoch 347/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3608 - accuracy: 0.8704\n",
      "Epoch 348/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3649 - accuracy: 0.8704\n",
      "Epoch 349/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3643 - accuracy: 0.8704\n",
      "Epoch 350/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3626 - accuracy: 0.8704\n",
      "Epoch 351/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3638 - accuracy: 0.8704\n",
      "Epoch 352/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3647 - accuracy: 0.8704\n",
      "Epoch 353/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.8704\n",
      "Epoch 354/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3616 - accuracy: 0.8704\n",
      "Epoch 355/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3594 - accuracy: 0.8704\n",
      "Epoch 356/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8704\n",
      "Epoch 357/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3641 - accuracy: 0.8704\n",
      "Epoch 358/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3635 - accuracy: 0.8704\n",
      "Epoch 359/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3641 - accuracy: 0.8704\n",
      "Epoch 360/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8704\n",
      "Epoch 361/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3606 - accuracy: 0.8704\n",
      "Epoch 362/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3633 - accuracy: 0.8704\n",
      "Epoch 363/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3630 - accuracy: 0.8704\n",
      "Epoch 364/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3616 - accuracy: 0.8704\n",
      "Epoch 365/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8704\n",
      "Epoch 366/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3609 - accuracy: 0.8704\n",
      "Epoch 367/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3613 - accuracy: 0.8704\n",
      "Epoch 368/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3643 - accuracy: 0.8704\n",
      "Epoch 369/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8704\n",
      "Epoch 370/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3624 - accuracy: 0.8704\n",
      "Epoch 371/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3643 - accuracy: 0.8704\n",
      "Epoch 372/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3619 - accuracy: 0.8704\n",
      "Epoch 373/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3594 - accuracy: 0.8704\n",
      "Epoch 374/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3635 - accuracy: 0.8704\n",
      "Epoch 375/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3607 - accuracy: 0.8704\n",
      "Epoch 376/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3589 - accuracy: 0.8704\n",
      "Epoch 377/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3617 - accuracy: 0.8704\n",
      "Epoch 378/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8704\n",
      "Epoch 379/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3624 - accuracy: 0.8704\n",
      "Epoch 380/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8704\n",
      "Epoch 381/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3622 - accuracy: 0.8704\n",
      "Epoch 382/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3640 - accuracy: 0.8704\n",
      "Epoch 383/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3588 - accuracy: 0.8704\n",
      "Epoch 384/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3627 - accuracy: 0.8704\n",
      "Epoch 385/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3592 - accuracy: 0.8704\n",
      "Epoch 386/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3583 - accuracy: 0.8704\n",
      "Epoch 387/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3600 - accuracy: 0.8704\n",
      "Epoch 388/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3594 - accuracy: 0.8704\n",
      "Epoch 389/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8704\n",
      "Epoch 390/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3628 - accuracy: 0.8704\n",
      "Epoch 391/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8704\n",
      "Epoch 392/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8704\n",
      "Epoch 393/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3583 - accuracy: 0.8704\n",
      "Epoch 394/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8704\n",
      "Epoch 395/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3602 - accuracy: 0.8704\n",
      "Epoch 396/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3641 - accuracy: 0.8704\n",
      "Epoch 397/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3612 - accuracy: 0.8704\n",
      "Epoch 398/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3620 - accuracy: 0.8704\n",
      "Epoch 399/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3637 - accuracy: 0.8704\n",
      "Epoch 400/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3601 - accuracy: 0.8704\n",
      "Epoch 401/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3621 - accuracy: 0.8704\n",
      "Epoch 402/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3602 - accuracy: 0.8704\n",
      "Epoch 403/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8704\n",
      "Epoch 404/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3610 - accuracy: 0.8704\n",
      "Epoch 405/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3600 - accuracy: 0.8704\n",
      "Epoch 406/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8704\n",
      "Epoch 407/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3605 - accuracy: 0.8704\n",
      "Epoch 408/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3608 - accuracy: 0.8704\n",
      "Epoch 409/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8704\n",
      "Epoch 410/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.8704\n",
      "Epoch 411/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8704\n",
      "Epoch 412/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3605 - accuracy: 0.8704\n",
      "Epoch 413/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3610 - accuracy: 0.8704\n",
      "Epoch 414/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3608 - accuracy: 0.8704\n",
      "Epoch 415/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3622 - accuracy: 0.8704\n",
      "Epoch 416/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8704\n",
      "Epoch 417/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3596 - accuracy: 0.8704\n",
      "Epoch 418/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3631 - accuracy: 0.8704\n",
      "Epoch 419/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.8704\n",
      "Epoch 420/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3573 - accuracy: 0.8704\n",
      "Epoch 421/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3629 - accuracy: 0.8704\n",
      "Epoch 422/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3603 - accuracy: 0.8704\n",
      "Epoch 423/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3627 - accuracy: 0.8704\n",
      "Epoch 424/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3606 - accuracy: 0.8704\n",
      "Epoch 425/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3586 - accuracy: 0.8704\n",
      "Epoch 426/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3606 - accuracy: 0.8704\n",
      "Epoch 427/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8704\n",
      "Epoch 428/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8704\n",
      "Epoch 429/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3615 - accuracy: 0.8704\n",
      "Epoch 430/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3588 - accuracy: 0.8704\n",
      "Epoch 431/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3629 - accuracy: 0.8704\n",
      "Epoch 432/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8704\n",
      "Epoch 433/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8704\n",
      "Epoch 434/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3638 - accuracy: 0.8704\n",
      "Epoch 435/3000\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.3650 - accuracy: 0.8704\n",
      "Epoch 436/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3639 - accuracy: 0.8704\n",
      "Epoch 437/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8704\n",
      "Epoch 438/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3632 - accuracy: 0.8704\n",
      "Epoch 439/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3612 - accuracy: 0.8704\n",
      "Epoch 440/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3631 - accuracy: 0.8704\n",
      "Epoch 441/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3599 - accuracy: 0.8704\n",
      "Epoch 442/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3593 - accuracy: 0.8704\n",
      "Epoch 443/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3600 - accuracy: 0.8704\n",
      "Epoch 444/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3619 - accuracy: 0.8704\n",
      "Epoch 445/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3598 - accuracy: 0.8704\n",
      "Epoch 446/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.8704\n",
      "Epoch 447/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3629 - accuracy: 0.8704\n",
      "Epoch 448/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3594 - accuracy: 0.8704\n",
      "Epoch 449/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3609 - accuracy: 0.8704\n",
      "Epoch 450/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3604 - accuracy: 0.8704\n",
      "Epoch 451/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3614 - accuracy: 0.8704\n",
      "Epoch 452/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3608 - accuracy: 0.8704\n",
      "Epoch 453/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8704\n",
      "Epoch 454/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8704\n",
      "Epoch 455/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3645 - accuracy: 0.8704\n",
      "Epoch 456/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3594 - accuracy: 0.8704\n",
      "Epoch 457/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3598 - accuracy: 0.8704\n",
      "Epoch 458/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3629 - accuracy: 0.8704\n",
      "Epoch 459/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3628 - accuracy: 0.8704\n",
      "Epoch 460/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3641 - accuracy: 0.8704\n",
      "Epoch 461/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3626 - accuracy: 0.8704\n",
      "Epoch 462/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3577 - accuracy: 0.8704\n",
      "Epoch 463/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3622 - accuracy: 0.8704\n",
      "Epoch 464/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3621 - accuracy: 0.8704\n",
      "Epoch 465/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3595 - accuracy: 0.8704\n",
      "Epoch 466/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3568 - accuracy: 0.8704\n",
      "Epoch 467/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3602 - accuracy: 0.8704\n",
      "Epoch 468/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3605 - accuracy: 0.8704\n",
      "Epoch 469/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3589 - accuracy: 0.8704\n",
      "Epoch 470/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3622 - accuracy: 0.8704\n",
      "Epoch 471/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3570 - accuracy: 0.8704\n",
      "Epoch 472/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3577 - accuracy: 0.8704\n",
      "Epoch 473/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8704\n",
      "Epoch 474/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3609 - accuracy: 0.8704\n",
      "Epoch 475/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3592 - accuracy: 0.8704\n",
      "Epoch 476/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3597 - accuracy: 0.8704\n",
      "Epoch 477/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8704\n",
      "Epoch 478/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3630 - accuracy: 0.8704\n",
      "Epoch 479/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3607 - accuracy: 0.8704\n",
      "Epoch 480/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3593 - accuracy: 0.8704\n",
      "Epoch 481/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3586 - accuracy: 0.8704\n",
      "Epoch 482/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3654 - accuracy: 0.8704\n",
      "Epoch 483/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3586 - accuracy: 0.8704\n",
      "Epoch 484/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8704\n",
      "Epoch 485/3000\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.3584 - accuracy: 0.8704\n",
      "Epoch 486/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3589 - accuracy: 0.8704\n",
      "Epoch 487/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3601 - accuracy: 0.8704\n",
      "Epoch 488/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3570 - accuracy: 0.8704\n",
      "Epoch 489/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8704\n",
      "Epoch 490/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3610 - accuracy: 0.8704\n",
      "Epoch 491/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3619 - accuracy: 0.8704\n",
      "Epoch 492/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3607 - accuracy: 0.8704\n",
      "Epoch 493/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3606 - accuracy: 0.8704\n",
      "Epoch 494/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3615 - accuracy: 0.8704\n",
      "Epoch 495/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3590 - accuracy: 0.8704\n",
      "Epoch 496/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3605 - accuracy: 0.8704\n",
      "Epoch 497/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3635 - accuracy: 0.8704\n",
      "Epoch 498/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3627 - accuracy: 0.8704\n",
      "Epoch 499/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3608 - accuracy: 0.8704\n",
      "Epoch 500/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3600 - accuracy: 0.8704\n",
      "Epoch 501/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3603 - accuracy: 0.8704\n",
      "Epoch 502/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3604 - accuracy: 0.8704\n",
      "Epoch 503/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3621 - accuracy: 0.8704\n",
      "Epoch 504/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3637 - accuracy: 0.8704\n",
      "Epoch 505/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3591 - accuracy: 0.8704\n",
      "Epoch 506/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3603 - accuracy: 0.8704\n",
      "Epoch 507/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3621 - accuracy: 0.8704\n",
      "Epoch 508/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3632 - accuracy: 0.8704\n",
      "Epoch 509/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3574 - accuracy: 0.8704\n",
      "Epoch 510/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3612 - accuracy: 0.8704\n",
      "Epoch 511/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3580 - accuracy: 0.8704\n",
      "Epoch 512/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3633 - accuracy: 0.8704\n",
      "Epoch 513/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3571 - accuracy: 0.8704\n",
      "Epoch 514/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8704\n",
      "Epoch 515/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3625 - accuracy: 0.8704\n",
      "Epoch 516/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3622 - accuracy: 0.8704\n",
      "Epoch 517/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8704\n",
      "Epoch 518/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3592 - accuracy: 0.8704\n",
      "Epoch 519/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3599 - accuracy: 0.8704\n",
      "Epoch 520/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3628 - accuracy: 0.8704\n",
      "Epoch 521/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3583 - accuracy: 0.8704\n",
      "Epoch 522/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3621 - accuracy: 0.8704\n",
      "Epoch 523/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3638 - accuracy: 0.8704\n",
      "Epoch 524/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3609 - accuracy: 0.8704\n",
      "Epoch 525/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3588 - accuracy: 0.8704\n",
      "Epoch 526/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8704\n",
      "Epoch 527/3000\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 0.3620 - accuracy: 0.8704\n",
      "Epoch 528/3000\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.3623 - accuracy: 0.8704\n",
      "Epoch 529/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3611 - accuracy: 0.8704\n",
      "Epoch 530/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3604 - accuracy: 0.8704\n",
      "Epoch 531/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3587 - accuracy: 0.8704\n",
      "Epoch 532/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3637 - accuracy: 0.8704\n",
      "Epoch 533/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3570 - accuracy: 0.8704\n",
      "Epoch 534/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3596 - accuracy: 0.8704\n",
      "Epoch 535/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3551 - accuracy: 0.8704\n",
      "Epoch 536/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3596 - accuracy: 0.8704\n",
      "Epoch 537/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3596 - accuracy: 0.8704\n",
      "Epoch 538/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3596 - accuracy: 0.8704\n",
      "Epoch 539/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3624 - accuracy: 0.8704\n",
      "Epoch 540/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3644 - accuracy: 0.8704\n",
      "Epoch 541/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3597 - accuracy: 0.8704\n",
      "Epoch 542/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3600 - accuracy: 0.8704\n",
      "Epoch 543/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3633 - accuracy: 0.8704\n",
      "Epoch 544/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3620 - accuracy: 0.8704\n",
      "Epoch 545/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3586 - accuracy: 0.8704\n",
      "Epoch 546/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3601 - accuracy: 0.8704\n",
      "Epoch 547/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.8704\n",
      "Epoch 548/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3613 - accuracy: 0.8704\n",
      "Epoch 549/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3617 - accuracy: 0.8704\n",
      "Epoch 550/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3576 - accuracy: 0.8704\n",
      "Epoch 551/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3641 - accuracy: 0.8704\n",
      "Epoch 552/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3597 - accuracy: 0.8704\n",
      "Epoch 553/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3589 - accuracy: 0.8704\n",
      "Epoch 554/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3591 - accuracy: 0.8704\n",
      "Epoch 555/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.8704\n",
      "Epoch 556/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3594 - accuracy: 0.8704\n",
      "Epoch 557/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3630 - accuracy: 0.8704\n",
      "Epoch 558/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3596 - accuracy: 0.8704\n",
      "Epoch 559/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3623 - accuracy: 0.8704\n",
      "Epoch 560/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3588 - accuracy: 0.8704\n",
      "Epoch 561/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3609 - accuracy: 0.8704\n",
      "Epoch 562/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3599 - accuracy: 0.8704\n",
      "Epoch 563/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8704\n",
      "Epoch 564/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3612 - accuracy: 0.8704\n",
      "Epoch 565/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3628 - accuracy: 0.8704\n",
      "Epoch 566/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3613 - accuracy: 0.8704\n",
      "Epoch 567/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3570 - accuracy: 0.8704\n",
      "Epoch 568/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.8704\n",
      "Epoch 569/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3609 - accuracy: 0.8704\n",
      "Epoch 570/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.8704\n",
      "Epoch 571/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3590 - accuracy: 0.8704\n",
      "Epoch 572/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3604 - accuracy: 0.8704\n",
      "Epoch 573/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3568 - accuracy: 0.8704\n",
      "Epoch 574/3000\n",
      "399/399 [==============================] - 1s 1ms/step - loss: 0.3591 - accuracy: 0.8704\n",
      "Epoch 575/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3588 - accuracy: 0.8704\n",
      "Epoch 576/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3596 - accuracy: 0.8704\n",
      "Epoch 577/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8704\n",
      "Epoch 578/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8704\n",
      "Epoch 579/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3608 - accuracy: 0.8704\n",
      "Epoch 580/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3606 - accuracy: 0.8704\n",
      "Epoch 581/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3617 - accuracy: 0.8704\n",
      "Epoch 582/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3606 - accuracy: 0.8704\n",
      "Epoch 583/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3574 - accuracy: 0.8704\n",
      "Epoch 584/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3619 - accuracy: 0.8704\n",
      "Epoch 585/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3627 - accuracy: 0.8704\n",
      "Epoch 586/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3613 - accuracy: 0.8704\n",
      "Epoch 587/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3614 - accuracy: 0.8704\n",
      "Epoch 588/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3627 - accuracy: 0.8704\n",
      "Epoch 589/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3631 - accuracy: 0.8704\n",
      "Epoch 590/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3613 - accuracy: 0.8704\n",
      "Epoch 591/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3612 - accuracy: 0.8704\n",
      "Epoch 592/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3600 - accuracy: 0.8704\n",
      "Epoch 593/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8704\n",
      "Epoch 594/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3593 - accuracy: 0.8704\n",
      "Epoch 595/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3591 - accuracy: 0.8704\n",
      "Epoch 596/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3640 - accuracy: 0.8704\n",
      "Epoch 597/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3628 - accuracy: 0.8704\n",
      "Epoch 598/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3599 - accuracy: 0.8704\n",
      "Epoch 599/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3605 - accuracy: 0.8704\n",
      "Epoch 600/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3596 - accuracy: 0.8704\n",
      "Epoch 601/3000\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.3572 - accuracy: 0.8704\n",
      "Epoch 602/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3619 - accuracy: 0.8704\n",
      "Epoch 603/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3623 - accuracy: 0.8704\n",
      "Epoch 604/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3599 - accuracy: 0.8704\n",
      "Epoch 605/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3603 - accuracy: 0.8704\n",
      "Epoch 606/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3607 - accuracy: 0.8704\n",
      "Epoch 607/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3609 - accuracy: 0.8704\n",
      "Epoch 608/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3597 - accuracy: 0.8704\n",
      "Epoch 609/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3596 - accuracy: 0.8704\n",
      "Epoch 610/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3600 - accuracy: 0.8704\n",
      "Epoch 611/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3604 - accuracy: 0.8704\n",
      "Epoch 612/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3601 - accuracy: 0.8704\n",
      "Epoch 613/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3642 - accuracy: 0.8704\n",
      "Epoch 614/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8704\n",
      "Epoch 615/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3604 - accuracy: 0.8704\n",
      "Epoch 616/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3584 - accuracy: 0.8704\n",
      "Epoch 617/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3595 - accuracy: 0.8704\n",
      "Epoch 618/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3582 - accuracy: 0.8704\n",
      "Epoch 619/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3581 - accuracy: 0.8704\n",
      "Epoch 620/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3642 - accuracy: 0.8704\n",
      "Epoch 621/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8704\n",
      "Epoch 622/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3613 - accuracy: 0.8704\n",
      "Epoch 623/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3584 - accuracy: 0.8704\n",
      "Epoch 624/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3639 - accuracy: 0.8704\n",
      "Epoch 625/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3613 - accuracy: 0.8704\n",
      "Epoch 626/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3552 - accuracy: 0.8704\n",
      "Epoch 627/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3592 - accuracy: 0.8704\n",
      "Epoch 628/3000\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3612 - accuracy: 0.8704\n",
      "Epoch 629/3000\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 0.3646 - accuracy: 0.8704\n",
      "Epoch 630/3000\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.3604 - accuracy: 0.8704\n",
      "Epoch 631/3000\n",
      " 34/399 [=>............................] - ETA: 1s - loss: 0.3595 - accuracy: 0.8735"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m classifier\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Fitting the ANN to the Training set\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2452\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2449\u001b[0m \u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m-> 2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mgraph_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2676\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m   filtered_flat_args \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2676\u001b[0m   cache_key, cache_key_deletion_observer \u001b[38;5;241m=\u001b[39m \u001b[43mfunction_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_cache_key\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2677\u001b[0m \u001b[43m      \u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2679\u001b[0m   cache_key, cache_key_deletion_observer \u001b[38;5;241m=\u001b[39m function_context\u001b[38;5;241m.\u001b[39mmake_cache_key(\n\u001b[1;32m   2680\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflat_input_signature)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function_context.py:130\u001b[0m, in \u001b[0;36mmake_cache_key\u001b[0;34m(args, include_tensor_ranks_only)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m\"\"\"Computes the cache key given the function arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m signature_context \u001b[38;5;241m=\u001b[39m trace_type\u001b[38;5;241m.\u001b[39mSignatureContext(\n\u001b[1;32m    129\u001b[0m     include_tensor_ranks_only)\n\u001b[0;32m--> 130\u001b[0m function_signature \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_function_signature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function_cache\u001b[38;5;241m.\u001b[39mFunctionCacheKey(\n\u001b[1;32m    133\u001b[0m     function_signature,\n\u001b[1;32m    134\u001b[0m     make_function_context()), signature_context\u001b[38;5;241m.\u001b[39mdeletion_observer\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/trace_type/signature_builder.py:154\u001b[0m, in \u001b[0;36mmake_function_signature\u001b[0;34m(function_args, signature_context)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_function_signature\u001b[39m(\n\u001b[1;32m    143\u001b[0m     function_args,\n\u001b[1;32m    144\u001b[0m     signature_context: SignatureContext) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m trace\u001b[38;5;241m.\u001b[39mTraceType:\n\u001b[1;32m    145\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns the trace type specification of a function's arguments.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    A TraceType object representing all the given inputs.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_trace_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/trace_type/signature_builder.py:110\u001b[0m, in \u001b[0;36mcreate_trace_type\u001b[0;34m(obj, context)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mNamedTuple(\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mtype\u001b[39m(obj), \u001b[38;5;28mtuple\u001b[39m(create_trace_type(c, context) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m obj))\n\u001b[1;32m    109\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdefault_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTuple\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcreate_trace_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    113\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mDict(\n\u001b[1;32m    114\u001b[0m       {k: create_trace_type(obj[k], context) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m obj})\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/trace_type/signature_builder.py:110\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mNamedTuple(\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mtype\u001b[39m(obj), \u001b[38;5;28mtuple\u001b[39m(create_trace_type(c, context) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m obj))\n\u001b[1;32m    109\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mTuple(\u001b[38;5;241m*\u001b[39m(\u001b[43mcreate_trace_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m obj))\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    113\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mDict(\n\u001b[1;32m    114\u001b[0m       {k: create_trace_type(obj[k], context) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m obj})\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/trace_type/signature_builder.py:110\u001b[0m, in \u001b[0;36mcreate_trace_type\u001b[0;34m(obj, context)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mNamedTuple(\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mtype\u001b[39m(obj), \u001b[38;5;28mtuple\u001b[39m(create_trace_type(c, context) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m obj))\n\u001b[1;32m    109\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdefault_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTuple\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcreate_trace_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    113\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mDict(\n\u001b[1;32m    114\u001b[0m       {k: create_trace_type(obj[k], context) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m obj})\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/trace_type/signature_builder.py:110\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mNamedTuple(\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28mtype\u001b[39m(obj), \u001b[38;5;28mtuple\u001b[39m(create_trace_type(c, context) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m obj))\n\u001b[1;32m    109\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mTuple(\u001b[38;5;241m*\u001b[39m(\u001b[43mcreate_trace_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m obj))\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    113\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m default_types\u001b[38;5;241m.\u001b[39mDict(\n\u001b[1;32m    114\u001b[0m       {k: create_trace_type(obj[k], context) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m obj})\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/trace_type/signature_builder.py:99\u001b[0m, in \u001b[0;36mcreate_trace_type\u001b[0;34m(obj, context)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_trace_type\u001b[39m(obj: Any,\n\u001b[1;32m     88\u001b[0m                       context: SignatureContext) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m trace\u001b[38;5;241m.\u001b[39mTraceType:\n\u001b[1;32m     89\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a TraceType corresponding to the object based on the context.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    A TraceType object representing the given object.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSupportsTracingProtocol\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m__tf_tracing_type__(context)\n\u001b[1;32m    102\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/typing.py:1145\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__instancecheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, instance):\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;66;03m# We need this method for situations where attributes are\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;66;03m# assigned in __init__.\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_protocol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m-> 1145\u001b[0m             \u001b[43m_is_callable_members_only\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m             \u001b[38;5;28missubclass\u001b[39m(instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, \u001b[38;5;28mcls\u001b[39m)):\n\u001b[1;32m   1147\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_protocol:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/typing.py:1084\u001b[0m, in \u001b[0;36m_is_callable_members_only\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_callable_members_only\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# PEP 544 prohibits using issubclass() with protocols that have non-method members.\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(callable(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, attr, \u001b[38;5;28;01mNone\u001b[39;00m)) \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_get_protocol_attrs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/typing.py:1077\u001b[0m, in \u001b[0;36m_get_protocol_attrs\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     annotations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(base, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__annotations__\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n\u001b[1;32m   1076\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(base\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(annotations\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m-> 1077\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mattr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_abc_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m attr \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m EXCLUDED_ATTRIBUTES:\n\u001b[1;32m   1078\u001b[0m             attrs\u001b[38;5;241m.\u001b[39madd(attr)\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attrs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#ARTIFICIAL NEURAL NETWORK\n",
    "\n",
    "import tensorflow as tf  \n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "tf.random.set_seed(124)\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 14,kernel_initializer='uniform', activation = 'relu', input_dim = 14))\n",
    "classifier.add(Dropout(rate = 0.2))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 14,kernel_initializer='uniform', activation = 'relu'))\n",
    "classifier.add(Dropout(rate = 0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7308b64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import statistics as st\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_predicted_class = (y_pred>(st.median(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6ae8b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kds\n",
    "kds.metrics.plot_lift(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
